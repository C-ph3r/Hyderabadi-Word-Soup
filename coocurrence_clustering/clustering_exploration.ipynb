{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: What dishes are mentioned together in the reviews? Do they form clusters? Can you identify cuisine types based on those clusters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\msard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import os\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import networkx as nx\n",
    "from matplotlib.colors import ListedColormap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import circlify as circ\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from unidecode import unidecode\n",
    "\n",
    "sns.set_context(font_scale=1.2, context='paper')\n",
    "\n",
    "import pycirclize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('C:/Users/msard/OneDrive/Desktop/Data Science/Fall 2024/Text Mining/Hyderabadi-Word-Soup/data_hyderabad/10k_reviews.csv')\n",
    "restaurants = pd.read_csv('C:/Users/msard/OneDrive/Desktop/Data Science/Fall 2024/Text Mining/Hyderabadi-Word-Soup/data_hyderabad/105_restaurants.csv')\n",
    "\n",
    "#print(reviews.info())\n",
    "#print(restaurants.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Cuisines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>Chinese, Continental, Kebab, European, South I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>Chinese, Continental, Kebab, European, South I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>Chinese, Continental, Kebab, European, South I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>Chinese, Continental, Kebab, European, South I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>Chinese, Continental, Kebab, European, South I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  The ambience was good, food was quite good . h...   \n",
       "1  Ambience is too good for a pleasant evening. S...   \n",
       "2  A must try.. great food great ambience. Thnx f...   \n",
       "3  Soumen das and Arun was a great guy. Only beca...   \n",
       "4  Food is good.we ordered Kodi drumsticks and ba...   \n",
       "\n",
       "                                            Cuisines  \n",
       "0  Chinese, Continental, Kebab, European, South I...  \n",
       "1  Chinese, Continental, Kebab, European, South I...  \n",
       "2  Chinese, Continental, Kebab, European, South I...  \n",
       "3  Chinese, Continental, Kebab, European, South I...  \n",
       "4  Chinese, Continental, Kebab, European, South I...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drops unnecessary columns and null rows\n",
    "reviews.drop(['Reviewer', 'Metadata', 'Time', 'Pictures', 'Rating'], axis=1, inplace=True)\n",
    "reviews.dropna(subset=['Review'], inplace=True)\n",
    "\n",
    "restaurants.drop(['Links', 'Cost', 'Collections', 'Timings'], axis=1, inplace=True)\n",
    "restaurants.dropna(subset=['Name', 'Cuisines'], inplace=True)\n",
    "\n",
    "# Merges the cuisines column with the reviews\n",
    "reviews = reviews.merge(restaurants[['Name', 'Cuisines']], \n",
    "                                      left_on='Restaurant', right_on='Name', \n",
    "                                      how='left').drop(columns=['Name'])\n",
    "\n",
    "reviews.drop(['Restaurant'], axis=1, inplace=True)\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Cuisines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  The ambience was good, food was quite good . h...   \n",
       "1  Ambience is too good for a pleasant evening. S...   \n",
       "2  A must try.. great food great ambience. Thnx f...   \n",
       "3  Soumen das and Arun was a great guy. Only beca...   \n",
       "4  Food is good.we ordered Kodi drumsticks and ba...   \n",
       "\n",
       "                                            Cuisines  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Cuisines into lists\n",
    "reviews['Cuisines'] = reviews['Cuisines'].str.split(', ')\n",
    "\n",
    "# Step 1: Find all unique cuisines\n",
    "unique_cuisines = sorted(set(cuisine for sublist in reviews['Cuisines'] for cuisine in sublist))\n",
    "\n",
    "# Step 2: Create a binary vector for each row\n",
    "def create_binary_vector(cuisines, all_cuisines):\n",
    "    return [1 if cuisine in cuisines else 0 for cuisine in all_cuisines]\n",
    "\n",
    "# Step 3: Apply the function to each row and store it in the 'Cuisines' column\n",
    "reviews['Cuisines'] = reviews['Cuisines'].apply(lambda x: create_binary_vector(x, unique_cuisines))\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_cleaner(raw_text, \n",
    "            no_emojis = True, \n",
    "            no_hashtags = True,\n",
    "            hashtag_retain_words = True,\n",
    "            no_newlines = True,\n",
    "            no_urls = True,\n",
    "            no_punctuation = True):\n",
    "    \n",
    "    #patterns\n",
    "    newline_pattern = \"(\\\\n)\"\n",
    "    hashtags_at_pattern = \"([#\\@@\\u0040\\uFF20\\uFE6B])\"\n",
    "    hashtags_ats_and_word_pattern = \"([#@]\\w+)\"\n",
    "    emojis_pattern = \"([\\u2600-\\u27FF])\"\n",
    "    url_pattern = \"(?:\\w+:\\/{2})?(?:www)?(?:\\.)?([a-z\\d]+)(?:\\.)([a-z\\d\\.]{2,})(\\/[a-zA-Z\\/\\d]+)?\" ##Note that this URL pattern is *even better*\n",
    "    punctuation_pattern = \"[\\u0021-\\u0026\\u0028-\\u002C\\u002E-\\u002F\\u003A-\\u003F\\u005B-\\u005F\\u2010-\\u2028\\ufeff`]+\"\n",
    "    apostrophe_pattern = \"'(?=[A-Z\\s])|(?<=[a-z\\.\\?\\!\\,\\s])'\"\n",
    "    separated_words_pattern = \"(?<=\\w\\s)([A-Z]\\s){2,}\"\n",
    "    ##note that this punctuation_pattern doesn't capture ' this time to allow our tokenizer to separate \"don't\" into [\"do\", \"n't\"]\n",
    "    \n",
    "    if no_emojis == True:\n",
    "        clean_text = re.sub(emojis_pattern,\"\",raw_text)\n",
    "    else:\n",
    "        clean_text = raw_text\n",
    "\n",
    "    if no_hashtags == True:\n",
    "        if hashtag_retain_words == True:\n",
    "            clean_text = re.sub(hashtags_at_pattern,\"\",clean_text)\n",
    "        else:\n",
    "            clean_text = re.sub(hashtags_ats_and_word_pattern,\"\",clean_text)\n",
    "        \n",
    "    if no_newlines == True:\n",
    "        clean_text = re.sub(newline_pattern,\" \",clean_text)\n",
    "\n",
    "    if no_urls == True:\n",
    "        clean_text = re.sub(url_pattern,\"\",clean_text)\n",
    "    \n",
    "    if no_punctuation == True:\n",
    "        clean_text = re.sub(punctuation_pattern,\"\",clean_text)\n",
    "        clean_text = re.sub(apostrophe_pattern,\"\",clean_text)\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "def lemmatize_all(token, list_pos=[\"n\",\"v\",\"a\",\"r\",\"s\"]):\n",
    "    \n",
    "    wordnet_lem = nltk.stem.WordNetLemmatizer()\n",
    "    for arg_1 in list_pos:\n",
    "        token = wordnet_lem.lemmatize(token, arg_1)\n",
    "    return token\n",
    "\n",
    "def main_pipeline(raw_text, \n",
    "                  print_output = True, \n",
    "                  no_stopwords = True,\n",
    "                  custom_stopwords = [],\n",
    "                  convert_diacritics = True, \n",
    "                  lowercase = True, \n",
    "                  lemmatized = True,\n",
    "                  list_pos = [\"n\",\"v\",\"a\",\"r\",\"s\"],\n",
    "                  stemmed = False, \n",
    "                  pos_tags_list = \"no_pos\",\n",
    "                  tokenized_output = False,\n",
    "                  **kwargs):\n",
    "    \n",
    "    \"\"\"Preprocess strings according to the parameters\"\"\"\n",
    "\n",
    "    clean_text = regex_cleaner(raw_text, **kwargs)\n",
    "    tokenized_text = nltk.tokenize.word_tokenize(clean_text)\n",
    "\n",
    "    tokenized_text = [re.sub(\"'m\",\"am\",token) for token in tokenized_text]\n",
    "    tokenized_text = [re.sub(\"n't\",\"not\",token) for token in tokenized_text]\n",
    "    tokenized_text = [re.sub(\"'s\",\"is\",token) for token in tokenized_text]\n",
    "\n",
    "    if no_stopwords == True:\n",
    "        stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "        tokenized_text = [item for item in tokenized_text if item.lower() not in stopwords]\n",
    "    \n",
    "    if convert_diacritics == True:\n",
    "        tokenized_text = [unidecode(token) for token in tokenized_text]\n",
    "\n",
    "    if lemmatized == True:\n",
    "        tokenized_text = [lemmatize_all(token, list_pos=list_pos) for token in tokenized_text]\n",
    "    \n",
    "    if stemmed == True:\n",
    "        porterstemmer = nltk.stem.PorterStemmer()\n",
    "        tokenized_text = [porterstemmer.stem(token) for token in tokenized_text]\n",
    " \n",
    "    if no_stopwords == True:\n",
    "        tokenized_text = [item for item in tokenized_text if item.lower() not in custom_stopwords]\n",
    "\n",
    "    if pos_tags_list == \"pos_list\" or pos_tags_list == \"pos_tuples\" or pos_tags_list == \"pos_dictionary\":\n",
    "        pos_tuples = nltk.tag.pos_tag(tokenized_text)\n",
    "        pos_tags = [pos[1] for pos in pos_tuples]\n",
    "    \n",
    "    if lowercase == True:\n",
    "        tokenized_text = [item.lower() for item in tokenized_text]\n",
    "\n",
    "    if print_output == True:\n",
    "        print(raw_text)\n",
    "        print(tokenized_text)\n",
    "    \n",
    "    if pos_tags_list == \"pos_list\":\n",
    "        return (tokenized_text, pos_tags)\n",
    "    elif pos_tags_list == \"pos_tuples\":\n",
    "        return pos_tuples   \n",
    "    \n",
    "    else:\n",
    "        if tokenized_output == True:\n",
    "            return tokenized_text\n",
    "        else:\n",
    "            detokenizer = TreebankWordDetokenizer()\n",
    "            detokens = detokenizer.detokenize(tokenized_text)\n",
    "            return str(detokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Cuisines</th>\n",
       "      <th>Preproc_Review</th>\n",
       "      <th>Review_PoS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>ambience good food quite good saturday lunch c...</td>\n",
       "      <td>[(ambience, RB), (good, JJ), (food, NN), (quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>ambience good pleasant evening service prompt ...</td>\n",
       "      <td>[(Ambience, RB), (good, JJ), (pleasant, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>must try great food great ambience thnx servic...</td>\n",
       "      <td>[(must, MD), (try, VB), (great, JJ), (food, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>soumen das arun great guy behavior sincerety g...</td>\n",
       "      <td>[(Soumen, NNP), (das, NNS), (Arun, NNP), (grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>food ordered kodi drumsticks basket mutton bir...</td>\n",
       "      <td>[(Food, NN), (ordered, VBD), (Kodi, NNP), (dru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  The ambience was good, food was quite good . h...   \n",
       "1  Ambience is too good for a pleasant evening. S...   \n",
       "2  A must try.. great food great ambience. Thnx f...   \n",
       "3  Soumen das and Arun was a great guy. Only beca...   \n",
       "4  Food is good.we ordered Kodi drumsticks and ba...   \n",
       "\n",
       "                                            Cuisines  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "\n",
       "                                      Preproc_Review  \\\n",
       "0  ambience good food quite good saturday lunch c...   \n",
       "1  ambience good pleasant evening service prompt ...   \n",
       "2  must try great food great ambience thnx servic...   \n",
       "3  soumen das arun great guy behavior sincerety g...   \n",
       "4  food ordered kodi drumsticks basket mutton bir...   \n",
       "\n",
       "                                          Review_PoS  \n",
       "0  [(ambience, RB), (good, JJ), (food, NN), (quit...  \n",
       "1  [(Ambience, RB), (good, JJ), (pleasant, NN), (...  \n",
       "2  [(must, MD), (try, VB), (great, JJ), (food, NN...  \n",
       "3  [(Soumen, NNP), (das, NNS), (Arun, NNP), (grea...  \n",
       "4  [(Food, NN), (ordered, VBD), (Kodi, NNP), (dru...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"Preproc_Review\"] =\\\n",
    "      reviews[\"Review\"].apply(lambda content :\\\n",
    "                                                  main_pipeline(content, \n",
    "                                                                  print_output=False,\n",
    "                                                                  lemmatized=False,\n",
    "                                                                  lowercase=True,\n",
    "                                                                        tokenized_output=False),\n",
    "                                                                  )\n",
    "\n",
    "reviews[\"Review_PoS\"] =\\\n",
    "      reviews[\"Review\"].apply(lambda content :\\\n",
    "                                                  main_pipeline(content, \n",
    "                                                                  print_output=False,\n",
    "                                                                  lemmatized=False,\n",
    "                                                                  lowercase=False,\n",
    "                                                                  pos_tags_list=\"pos_tuples\"),\n",
    "                                                                  )\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(ngram_range=(1,2), token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), token_pattern=r\"(?u)\\b\\w+\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Cuisines</th>\n",
       "      <th>Preproc_Review</th>\n",
       "      <th>Review_PoS</th>\n",
       "      <th>Review_bow_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>ambience good food quite good saturday lunch c...</td>\n",
       "      <td>[(ambience, RB), (good, JJ), (food, NN), (quit...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>ambience good pleasant evening service prompt ...</td>\n",
       "      <td>[(Ambience, RB), (good, JJ), (pleasant, NN), (...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>must try great food great ambience thnx servic...</td>\n",
       "      <td>[(must, MD), (try, VB), (great, JJ), (food, NN...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>soumen das arun great guy behavior sincerety g...</td>\n",
       "      <td>[(Soumen, NNP), (das, NNS), (Arun, NNP), (grea...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>food ordered kodi drumsticks basket mutton bir...</td>\n",
       "      <td>[(Food, NN), (ordered, VBD), (Kodi, NNP), (dru...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  The ambience was good, food was quite good . h...   \n",
       "1  Ambience is too good for a pleasant evening. S...   \n",
       "2  A must try.. great food great ambience. Thnx f...   \n",
       "3  Soumen das and Arun was a great guy. Only beca...   \n",
       "4  Food is good.we ordered Kodi drumsticks and ba...   \n",
       "\n",
       "                                            Cuisines  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "\n",
       "                                      Preproc_Review  \\\n",
       "0  ambience good food quite good saturday lunch c...   \n",
       "1  ambience good pleasant evening service prompt ...   \n",
       "2  must try great food great ambience thnx servic...   \n",
       "3  soumen das arun great guy behavior sincerety g...   \n",
       "4  food ordered kodi drumsticks basket mutton bir...   \n",
       "\n",
       "                                          Review_PoS  \\\n",
       "0  [(ambience, RB), (good, JJ), (food, NN), (quit...   \n",
       "1  [(Ambience, RB), (good, JJ), (pleasant, NN), (...   \n",
       "2  [(must, MD), (try, VB), (great, JJ), (food, NN...   \n",
       "3  [(Soumen, NNP), (das, NNS), (Arun, NNP), (grea...   \n",
       "4  [(Food, NN), (ordered, VBD), (Kodi, NNP), (dru...   \n",
       "\n",
       "                                   Review_bow_vector  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_bow_td_matrix = bow_vectorizer.fit_transform(reviews[\"Preproc_Review\"]).toarray()\n",
    "reviews[\"Review_bow_vector\"] = reviews_bow_td_matrix.tolist()\n",
    "reviews_bow_word_list = bow_vectorizer.get_feature_names_out()\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Cuisines</th>\n",
       "      <th>Preproc_Review</th>\n",
       "      <th>Review_PoS</th>\n",
       "      <th>Review_bow_vector</th>\n",
       "      <th>Review_tfidf_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>ambience good food quite good saturday lunch c...</td>\n",
       "      <td>[(ambience, RB), (good, JJ), (food, NN), (quit...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>(0, 8031)\\t0.0567096946353229\\n  (0, 67501)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>ambience good pleasant evening service prompt ...</td>\n",
       "      <td>[(Ambience, RB), (good, JJ), (pleasant, NN), (...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>(0, 8031)\\t0.08084883167553647\\n  (0, 67501)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>must try great food great ambience thnx servic...</td>\n",
       "      <td>[(must, MD), (try, VB), (great, JJ), (food, NN...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>(0, 8031)\\t0.06303637505472821\\n  (0, 59669)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>soumen das arun great guy behavior sincerety g...</td>\n",
       "      <td>[(Soumen, NNP), (das, NNS), (Arun, NNP), (grea...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>(0, 67501)\\t0.0488960604396863\\n  (0, 59669)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>food ordered kodi drumsticks basket mutton bir...</td>\n",
       "      <td>[(Food, NN), (ordered, VBD), (Kodi, NNP), (dru...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>(0, 8031)\\t0.07412009791971721\\n  (0, 67501)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  The ambience was good, food was quite good . h...   \n",
       "1  Ambience is too good for a pleasant evening. S...   \n",
       "2  A must try.. great food great ambience. Thnx f...   \n",
       "3  Soumen das and Arun was a great guy. Only beca...   \n",
       "4  Food is good.we ordered Kodi drumsticks and ba...   \n",
       "\n",
       "                                            Cuisines  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "\n",
       "                                      Preproc_Review  \\\n",
       "0  ambience good food quite good saturday lunch c...   \n",
       "1  ambience good pleasant evening service prompt ...   \n",
       "2  must try great food great ambience thnx servic...   \n",
       "3  soumen das arun great guy behavior sincerety g...   \n",
       "4  food ordered kodi drumsticks basket mutton bir...   \n",
       "\n",
       "                                          Review_PoS  \\\n",
       "0  [(ambience, RB), (good, JJ), (food, NN), (quit...   \n",
       "1  [(Ambience, RB), (good, JJ), (pleasant, NN), (...   \n",
       "2  [(must, MD), (try, VB), (great, JJ), (food, NN...   \n",
       "3  [(Soumen, NNP), (das, NNS), (Arun, NNP), (grea...   \n",
       "4  [(Food, NN), (ordered, VBD), (Kodi, NNP), (dru...   \n",
       "\n",
       "                                   Review_bow_vector  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                 Review_tfidf_vector  \n",
       "0    (0, 8031)\\t0.0567096946353229\\n  (0, 67501)\\...  \n",
       "1    (0, 8031)\\t0.08084883167553647\\n  (0, 67501)...  \n",
       "2    (0, 8031)\\t0.06303637505472821\\n  (0, 59669)...  \n",
       "3    (0, 67501)\\t0.0488960604396863\\n  (0, 59669)...  \n",
       "4    (0, 8031)\\t0.07412009791971721\\n  (0, 67501)...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_tfidf_td_matrix = tfidf_vectorizer.fit_transform(reviews[\"Preproc_Review\"])\n",
    "reviews[\"Review_tfidf_vector\"] = [row for row in reviews_tfidf_td_matrix]\n",
    "reviews_tfidf_word_list = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq_calculator(td_matrix, word_list, df_output=True):\n",
    "    word_counts = np.sum(td_matrix, axis=0).tolist()\n",
    "    if df_output == False:\n",
    "        word_counts_dict = dict(zip(word_list, word_counts))\n",
    "        return word_counts_dict\n",
    "    else:\n",
    "        word_counts_df = pd.DataFrame({\"words\":word_list, \"frequency\":word_counts})\n",
    "        word_counts_df = word_counts_df.sort_values(by=[\"frequency\"], ascending=False)\n",
    "        return word_counts_df\n",
    "    \n",
    "def plot_term_frequency(df, nr_terms, df_name, show=True):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns_plot = sns.barplot(x='frequency', y='words', data=df.head(nr_terms))  # Plotting top 20 terms for better visualization\n",
    "    plt.title('Top 20 Term Frequencies of {}'.format(df_name))\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Words')\n",
    "    if show==True:\n",
    "        plt.show()\n",
    "\n",
    "    fig = sns_plot.get_figure()\n",
    "    plt.close()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...\n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...\n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...\n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...\n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...\n",
       "                              ...                        \n",
       "9950    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n",
       "9951    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n",
       "9952    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n",
       "9953    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n",
       "9954    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n",
       "Name: Cuisines, Length: 9955, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['Cuisines']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder for saving review visualizations\n",
    "folder_path = 'C:\\Users\\msard\\OneDrive\\Desktop\\Data Science\\Fall 2024\\Text Mining\\Hyderabadi-Word-Soup\\coocurrence_clustering\\visualizations'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Create directory for the visualizations\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Iterate through each cuisine type\n",
    "for cuisine_idx, cuisine_name in enumerate(reviews['Cuisines'].unique().tolist()):\n",
    "    \n",
    "    # Filter reviews for this cuisine\n",
    "    cuisine_reviews = reviews[reviews['Cuisines'].apply(lambda x: x[cuisine_idx] == 1)]\n",
    "    \n",
    "    # Aggregate the BoW vectors for the cuisine (summing over all reviews for this cuisine)\n",
    "    if len(cuisine_reviews) > 0:\n",
    "        cuisine_bow_vector_sum = np.sum(np.array(cuisine_reviews['Review_bow_vector'].tolist()), axis=0)\n",
    "        cuisine_bow_df = word_freq_calculator([cuisine_bow_vector_sum], reviews_bow_word_list)\n",
    "        \n",
    "        # Plot and save the BoW visualization\n",
    "        cuisine_bow_plot = plot_term_frequency(\n",
    "            cuisine_bow_df, 20,\n",
    "            f\"{cuisine_name} Cuisine - 20 Most Common Words (BoW)\",\n",
    "            show=False\n",
    "        )\n",
    "        cuisine_bow_plot.savefig(os.path.join(folder_path, f\"{cuisine_name}_BOW.png\"))\n",
    "\n",
    "        # Aggregate the TF-IDF vectors for the cuisine (summing over all reviews for this cuisine)\n",
    "        cuisine_tfidf_vector_sum = np.sum(np.array(cuisine_reviews['Review_tfidf_vector'].tolist()), axis=0)\n",
    "        cuisine_tfidf_df = word_freq_calculator([cuisine_tfidf_vector_sum], reviews_tfidf_word_list)\n",
    "        \n",
    "        # Plot and save the TF-IDF visualization\n",
    "        cuisine_tfidf_plot = plot_term_frequency(\n",
    "            cuisine_tfidf_df, 20,\n",
    "            f\"{cuisine_name} Cuisine - 20 Most Relevant Words (TF-IDF)\",\n",
    "            show=False\n",
    "        )\n",
    "        cuisine_tfidf_plot.savefig(os.path.join(folder_path, f\"{cuisine_name}_TFIDF.png\"))\n",
    "\n",
    "# Display completion message\n",
    "print(f\"Saved BoW and TF-IDF visualizations for each cuisine type in '{folder_path}' folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
